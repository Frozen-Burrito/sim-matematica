{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23d0284",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning\n",
    "\n",
    "Alumno: Fernando Mendoza Velasco\n",
    "Fecha: 17 de Marzo de 2025\n",
    "\n",
    "Un **algoritmo de Machine Learning** es un conjunto de reglas matem√°ticas que permiten a un modelo aprender patrones a partir de datos. Se pueden dividir en varias categor√≠as:\n",
    "\n",
    "### üìå **Tipos de Algoritmos:**\n",
    "\n",
    "1. **Aprendizaje Supervisado** (con etiquetas):\n",
    "   - Regresi√≥n Lineal\n",
    "   - Regresi√≥n Log√≠stica\n",
    "   - √Årboles de Decisi√≥n\n",
    "   - M√°quinas de Soporte Vectorial (SVM)\n",
    "   - Redes Neuronales\n",
    "\n",
    "2. **Aprendizaje No Supervisado** (sin etiquetas):\n",
    "   - Clustering (K-Means, DBSCAN, etc.)\n",
    "   - An√°lisis de Componentes Principales (PCA)\n",
    "\n",
    "3. **Aprendizaje por Refuerzo**\n",
    "   - Q-Learning\n",
    "   - Deep Q-Networks (DQN)\n",
    "   - El aprendizaje por refuerzo (Reinforcement Learning, RL) es un tipo de Machine Learning donde un agente aprende a tomar decisiones mediante prueba y error, recibiendo recompensas o penalizaciones seg√∫n sus acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e03fa3",
   "metadata": {},
   "source": [
    "## Modelos de Clasificaci√≥n\n",
    "\n",
    "Los modelos de **Clasificaci√≥n** son un tipo de aprendizaje supervisado que asignan una etiqueta a cada entrada. Algunos modelos de clasificaci√≥n comunes incluyen:\n",
    "\n",
    "### üè∑ **Modelos de Clasificaci√≥n Binaria**\n",
    "- **Regresi√≥n Log√≠stica** ‚Üí Predice dos clases (ejemplo: spam o no spam).\n",
    "- **√Årbol de Decisi√≥n** ‚Üí Divide los datos en nodos de decisi√≥n.\n",
    "- **M√°quinas de Soporte Vectorial (SVM)** ‚Üí Encuentra un hiperplano √≥ptimo para separar clases.\n",
    "\n",
    "### üè∑ **Modelos de Clasificaci√≥n Multiclase**\n",
    "- **K-Vecinos M√°s Cercanos (KNN)** ‚Üí Clasifica basado en los vecinos m√°s cercanos.\n",
    "- **Redes Neuronales** ‚Üí Modelos complejos que aprenden patrones en los datos.\n",
    "\n",
    "### üìä **Ejemplo Visual de Clasificaci√≥n con SVM**\n",
    "![Clasificaci√≥n SVM](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/640px-SVM_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2928ae8",
   "metadata": {},
   "source": [
    "## Decision Boundary\n",
    "- Un Decision Boundary es una l√≠nea o margen que separa las clases.\n",
    "- El algoritmo de clasificaci√≥n trata de encontrar el l√≠mite de decisi√≥n que ayude a distinguir entre las clases de manera perfecta o casi perfecta.\n",
    "- La regresi√≥n log√≠stica decide un ajuste adecuado al l√≠mite de decisi√≥n para que podamos predecir a qu√© clase corresponder√° un nuevo dato.\n",
    "\n",
    "![Aprendizaje Supervisado](https://miro.medium.com/v2/resize:fit:720/format:webp/1*kmMho6PkiVbOXKEYvguMOQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879020d1",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado\n",
    "\n",
    "El **Aprendizaje Supervisado** es una t√©cnica de Machine Learning en la que un modelo aprende a partir de ejemplos etiquetados.\n",
    "\n",
    "### üìå **Ejemplo de Aprendizaje Supervisado**\n",
    "- Entrenamos un modelo con im√°genes de **gatos** y **perros**.\n",
    "- Etiquetamos las im√°genes como ‚Äúgato‚Äù o ‚Äúperro‚Äù.\n",
    "- El modelo aprende a predecir la categor√≠a de nuevas im√°genes.\n",
    "\n",
    "![Aprendizaje Supervisado](https://miro.medium.com/v2/resize:fit:720/format:webp/1*3FgpptTWzpd2RLgKbV-HvA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d7209",
   "metadata": {},
   "source": [
    "## Fundamentos Matem√°ticos de la Regresi√≥n Log√≠stica\n",
    "\n",
    "La **regresi√≥n log√≠stica** es un modelo estad√≠stico que se utiliza para predecir una variable de respuesta binaria (0 o 1) a partir de una o m√°s variables independientes \\( X \\). A diferencia de la regresi√≥n lineal, la regresi√≥n log√≠stica usa la funci√≥n sigmoide para modelar la probabilidad de pertenencia a una de las clases.\n",
    "\n",
    "El modelo se expresa como:\n",
    "\n",
    "$$ P(y=1 | X) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}} $$\n",
    "\n",
    "Donde:\n",
    "- \\( y \\) es la variable dependiente binaria.\n",
    "- \\( X \\) es la matriz de caracter√≠sticas.\n",
    "- \\( theta \\) son los par√°metros del modelo.\n",
    "- \\( sigma \\) es la funci√≥n sigmoide.\n",
    "\n",
    "El objetivo es encontrar los valores √≥ptimos de \\( theta \\) que maximicen la probabilidad de clasificaci√≥n correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b445211",
   "metadata": {},
   "source": [
    "### Funci√≥n Sigmoide\n",
    "\n",
    "La **funci√≥n sigmoide** es utilizada en la regresi√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase. Convierte cualquier valor real en un valor en el rango \\( (0,1) \\), lo que lo hace ideal para problemas de clasificaci√≥n binaria.\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "Donde\n",
    "\n",
    "$$ z = X \\theta $$\n",
    "\n",
    "En nuestro modelo, la funci√≥n sigmoide toma como entrada la multiplicaci√≥n matricial entre las caracter√≠sticas (x) y los coeficientes (theta):\n",
    "\n",
    "$$ \\sigma(X \\theta) = \\frac{1}{1 + e^{-X \\theta}} $$\n",
    "![Funci√≥n Sigmoide](https://miro.medium.com/v2/resize:fit:640/format:webp/1*xTwaKZZsIRek8jzrNWRPzQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f92ac6",
   "metadata": {},
   "source": [
    "## Funci√≥n de Costo en Regresi√≥n Log√≠stica\n",
    "\n",
    "La funci√≥n de costo es una funci√≥n que mide el rendimiento de un modelo de aprendizaje autom√°tico para datos determinados.\n",
    "\n",
    "La funci√≥n de costo es b√°sicamente el c√°lculo del error entre los valores predichos y los valores esperados y lo presenta en forma de un √∫nico n√∫mero real.\n",
    "\n",
    "Mucha gente confunde la funci√≥n de costo con la funci√≥n de p√©rdida.\n",
    "\n",
    "Bueno, para decirlo en t√©rminos simples, la **funci√≥n de costo** es el promedio del error de n muestras en los datos y la **funci√≥n de p√©rdida** es el error de puntos de datos individuales. En otras palabras, la funci√≥n de p√©rdida es para un ejemplo de entrenamiento, la funci√≥n de costo es para todo el conjunto de entrenamiento.\n",
    "\n",
    "Profundiza: https://medium.com/analytics-vidhya/understanding-logistic-regression-b3c672deac04\n",
    "\n",
    "Para entrenar el modelo, utilizamos la funci√≥n de **log-verosimilitud**, que mide qu√© tan bien los par√°metros explican los datos:\n",
    "\n",
    "$$ \\ell(\\theta) = \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right] $$\n",
    "\n",
    "Sin embargo, en la pr√°ctica se minimiza la versi√≥n negativa de esta funci√≥n, conocida como **log-loss** o **binary cross-entropy**:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right] $$\n",
    "\n",
    "**Minimizar** esta funci√≥n equivale a encontrar los par√°metros √≥ptimos para el modelo log√≠stico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6cf6f",
   "metadata": {},
   "source": [
    "### Regularizaci√≥n en Regresi√≥n Log√≠stica\n",
    "\n",
    "Para evitar sobreajuste, a√±adimos un **t√©rmino de regularizaci√≥n** a la funci√≥n de costo. El m√©todo m√°s com√∫n es la **regularizaci√≥n L2 (Ridge)**, que penaliza grandes valores en los coeficientes:\n",
    "\n",
    "$$ R(\\theta) = \\frac{\\lambda}{2n} \\sum_{j=1}^{m} \\theta_j^2 $$\n",
    "\n",
    "Incorporando la regularizaci√≥n en la funci√≥n de costo:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(X_i \\theta) + (1 - y_i) \\log (1 - \\sigma(X_i \\theta)) \\right] + \\frac{\\lambda}{2n} \\sum_{j=1}^{m} \\theta_j^2 $$\n",
    "\n",
    "Donde \\( lambda \\) es el hiperpar√°metro que controla la intensidad de la regularizaci√≥n.\n",
    "\n",
    "Tambien puedes obtener el costo y la regularizaci√≥n aparte y sumarlos (te dejo el c√≥digo prellenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dc1ef",
   "metadata": {},
   "source": [
    "### Actividad. Diagn√≥stico de afecciones en tejido mamario.\n",
    "- Realiza las instrucciones propuestas en las celdas markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36b9b3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5     843786         M        12.45         15.70           82.57      477.1   \n",
       "6     844359         M        18.25         19.98          119.60     1040.0   \n",
       "7   84458202         M        13.71         20.83           90.20      577.9   \n",
       "8     844981         M        13.00         21.82           87.50      519.8   \n",
       "9   84501001         M        12.46         24.04           83.97      475.9   \n",
       "10    845636         M        16.02         23.24          102.70      797.8   \n",
       "11  84610002         M        15.78         17.89          103.60      781.0   \n",
       "12    846226         M        19.17         24.80          132.40     1123.0   \n",
       "13    846381         M        15.85         23.95          103.70      782.7   \n",
       "14  84667401         M        13.73         22.61           93.60      578.3   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "5           0.12780           0.17000         0.15780              0.08089   \n",
       "6           0.09463           0.10900         0.11270              0.07400   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "8           0.12730           0.19320         0.18590              0.09353   \n",
       "9           0.11860           0.23960         0.22730              0.08543   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "11          0.09710           0.12920         0.09954              0.06606   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "13          0.08401           0.10020         0.09938              0.05364   \n",
       "14          0.11310           0.22930         0.21280              0.08025   \n",
       "\n",
       "    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0   ...          17.33           184.60      2019.0            0.1622   \n",
       "1   ...          23.41           158.80      1956.0            0.1238   \n",
       "2   ...          25.53           152.50      1709.0            0.1444   \n",
       "3   ...          26.50            98.87       567.7            0.2098   \n",
       "4   ...          16.67           152.20      1575.0            0.1374   \n",
       "5   ...          23.75           103.40       741.6            0.1791   \n",
       "6   ...          27.66           153.20      1606.0            0.1442   \n",
       "7   ...          28.14           110.60       897.0            0.1654   \n",
       "8   ...          30.73           106.20       739.3            0.1703   \n",
       "9   ...          40.68            97.65       711.4            0.1853   \n",
       "10  ...          33.88           123.80      1150.0            0.1181   \n",
       "11  ...          27.28           136.50      1299.0            0.1396   \n",
       "12  ...          29.94           151.70      1332.0            0.1037   \n",
       "13  ...          27.66           112.00       876.5            0.1131   \n",
       "14  ...          32.01           108.80       697.7            0.1651   \n",
       "\n",
       "    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.6656           0.7119               0.26540          0.4601   \n",
       "1              0.1866           0.2416               0.18600          0.2750   \n",
       "2              0.4245           0.4504               0.24300          0.3613   \n",
       "3              0.8663           0.6869               0.25750          0.6638   \n",
       "4              0.2050           0.4000               0.16250          0.2364   \n",
       "5              0.5249           0.5355               0.17410          0.3985   \n",
       "6              0.2576           0.3784               0.19320          0.3063   \n",
       "7              0.3682           0.2678               0.15560          0.3196   \n",
       "8              0.5401           0.5390               0.20600          0.4378   \n",
       "9              1.0580           1.1050               0.22100          0.4366   \n",
       "10             0.1551           0.1459               0.09975          0.2948   \n",
       "11             0.5609           0.3965               0.18100          0.3792   \n",
       "12             0.3903           0.3639               0.17670          0.3176   \n",
       "13             0.1924           0.2322               0.11190          0.2809   \n",
       "14             0.7725           0.6943               0.22080          0.3596   \n",
       "\n",
       "    fractal_dimension_worst  Unnamed: 32  \n",
       "0                   0.11890          NaN  \n",
       "1                   0.08902          NaN  \n",
       "2                   0.08758          NaN  \n",
       "3                   0.17300          NaN  \n",
       "4                   0.07678          NaN  \n",
       "5                   0.12440          NaN  \n",
       "6                   0.08368          NaN  \n",
       "7                   0.11510          NaN  \n",
       "8                   0.10720          NaN  \n",
       "9                   0.20750          NaN  \n",
       "10                  0.08452          NaN  \n",
       "11                  0.10480          NaN  \n",
       "12                  0.10230          NaN  \n",
       "13                  0.06287          NaN  \n",
       "14                  0.14310          NaN  \n",
       "\n",
       "[15 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b2785",
   "metadata": {},
   "source": [
    "#### Obten los datos de entrada y de salida\n",
    "- Elimina las columnas innecesarias 'id', 'Unnamed: 32'\n",
    "- Convierte variable objetivo o dependiente \"diagn√≥stico\" a num√©rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17600ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocesamiento de datos\n",
    "df = df.drop([\"id\", \"Unnamed: 32\"], axis=1)  # Eliminar columnas irrelevantes\n",
    "df['diagnosis'] = df['diagnosis'].map({\"M\": 1, \"B\": 0})  # Convertir variable objetivo o dependiente \"diagn√≥stico\" a num√©rico\n",
    "display(df.head())\n",
    "# Obten X e y\n",
    "X = df.drop(columns=['diagnosis']).values\n",
    "y = df['diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b00a2",
   "metadata": {},
   "source": [
    "#### Separa los datos en conjuntos X_train, X_test, y_train, y_test para su estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82afea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n del conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad2f77",
   "metadata": {},
   "source": [
    "#### Estandariza los datos con StandardScaler\n",
    "La **estandarizaci√≥n** es un proceso de transformaci√≥n de datos en el que cada caracter√≠stica del conjunto de datos se ajusta para que tenga **media cero** y **varianza unitaria**. Esto es especialmente √∫til para algoritmos de aprendizaje autom√°tico que utilizan optimizaci√≥n basada en gradientes, como la **Regresi√≥n Log√≠stica**.\n",
    "\n",
    "Dado un conjunto de datos con caracter√≠sticas \\( X \\), cada valor \\( x_i \\) se transforma seg√∫n la siguiente ecuaci√≥n:\n",
    "\n",
    "$$\n",
    "x_{\\text{estandarizado}} = \\frac{x_i - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- (mu) es la **media** de la caracter√≠stica.\n",
    "- (sigma) es la **desviaci√≥n est√°ndar** de la caracter√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f981da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train, y_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d133d9",
   "metadata": {},
   "source": [
    "#### Define las funciones matem√°ticas del modelo\n",
    "- Define la funci√≥n sigmoide\n",
    "- Define la funci√≥n de regularizaci√≥n\n",
    "- Define la funci√≥n de costo. Retorna costo + regularizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ecc770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la funci√≥n sigmoide con entrada X @ theta\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Definir la funci√≥n de regularizaci√≥n L2\n",
    "def regularization(theta, lambda_reg, m):\n",
    "    return lambda_reg * np.sum(theta[1:m]**2) / (2 * m)\n",
    "\n",
    "# Definir la funci√≥n de costo con regularizaci√≥n\n",
    "def cost_function_reg(theta, X, y, lambda_reg=0.1):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ np.transpose(theta))\n",
    "    epsilon = 1e-5  # Para evitar log(0)\n",
    "    cost = - (np.dot(y, np.log(h + epsilon)) + np.dot((1 - y), np.log(1 - h + epsilon))) / m\n",
    "    return cost + regularization(theta, lambda_reg, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0ca78",
   "metadata": {},
   "source": [
    "#### Obten los coeficientes de la regresi√≥n logistica\n",
    "\n",
    "- En los datos `X` de entrenamiento, agrega una columna de unos al principio. \n",
    "    - Esto es un requisito de la funci√≥n `minimize` y sirve para el t√©rmino de sesgo en los datos de entrenamiento.\n",
    "- Crea un vector de ceros `theta_init` con la dimensi√≥n del n√∫mero total de columnas de `X` de entrenamiento\n",
    "- Realiza la optimizaci√≥n con `scipy.minimize` y obt√©n los coeficientes de la regresi√≥n logp√≠stica.\n",
    "    - Utiliza el m√©todo de BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0693437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes obtenidos con scipy: [ 0.47296772 -0.59015242  0.54629322 -0.41529137 -0.17320684  0.46002746\n",
      " -2.61115961  2.16474894  2.05715302 -0.11661401  0.05214688  2.59411907\n",
      " -0.83065273  0.41703908  2.47954181  0.41434456  0.39690339 -1.25615014\n",
      "  1.19680631 -0.70720624 -2.05733899  2.1633816   1.96894263  1.566969\n",
      "  2.3961446   0.59680602 -0.8920343   1.30973618  0.91284433  1.25509307\n",
      "  1.93220161]\n"
     ]
    }
   ],
   "source": [
    "# Agregar columna de unos para el t√©rmino de sesgo en los datos de entrenamiento\n",
    "X_train_bias_scaled = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
    "theta_init = np.zeros(X_train_bias_scaled.shape[1])\n",
    "\n",
    "# Optimizaci√≥n con scipy\n",
    "res = minimize(cost_function_reg, theta_init, args=(X_train_bias_scaled, y_train), method=\"BFGS\")\n",
    "theta_opt_scaled = res.x\n",
    "\n",
    "print('Coeficientes obtenidos con scipy:', theta_opt_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b68bb",
   "metadata": {},
   "source": [
    "### Eval√∫a la efectividad del modelo\n",
    "- En los datos X de prueba, agrega una columna de unos al principio. \n",
    "    - Esto para que tenga la misma dimensi√≥n que theta_opt_scaled y lo pueda procesar.\n",
    "- Utiliza la funci√≥n sigmoide y los coeficientes de la regresi√≥n log√≠stica para obtener las predicciones\n",
    "- Escala los datos con un umbral de 0.5 y guardalos en un vector  'y_pred_scaled'\n",
    "-   Esto significa que si son mayores o iguales a 0.5, la salida es 1. Si son menores, la salida es 0.\n",
    "- Muestra el vector  'y_pred_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7225eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluar la efectividad del modelo optimizado con scipy en los datos normalizados\n",
    "X_test_bias_scaled = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_prob_scaled = sigmoid(X_test_bias_scaled @ theta_opt_scaled)\n",
    "y_pred_scaled = [1 if y_pred >= 0.5 else 0 for y_pred in y_pred_prob_scaled ]\n",
    "y_pred_scaled[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baced2d",
   "metadata": {},
   "source": [
    "#### Eval√∫a el accuracy del modelo. \n",
    "##### ¬øQu√© es el Accuracy?\n",
    "El **accuracy** (precisi√≥n) es una m√©trica fundamental en Machine Learning que mide el porcentaje de predicciones correctas sobre el total de predicciones realizadas.\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{N√∫mero de predicciones correctas}}{\\text{N√∫mero total de predicciones}}\n",
    "$$\n",
    "\n",
    "o en t√©rminos de clasificaci√≥n binaria:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- **TP (True Positives)**: Casos positivos correctamente clasificados.\n",
    "- **TN (True Negatives)**: Casos negativos correctamente clasificados.\n",
    "- **FP (False Positives)**: Casos negativos incorrectamente clasificados como positivos.\n",
    "- **FN (False Negatives)**: Casos positivos incorrectamente clasificados como negativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37589888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n del modelo con scipy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "# Calcular precisi√≥n del modelo optimizado con scipy en datos normalizados\n",
    "accuracy_scipy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "print('Precisi√≥n del modelo con scipy:', accuracy_scipy_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f7bd9",
   "metadata": {},
   "source": [
    "### Actividad: Implementa la soluci√≥n en Sklearn y compara los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06568994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Comprueba tus resultados con la implementaci√≥n en sklearn. \n",
    "# Importar la regresi√≥n log√≠stica de scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear y entrenar el modelo de regresi√≥n log√≠stica con scikit-learn\n",
    "sklearn_model = LogisticRegression(penalty=\"l2\", max_iter=10_000)\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "# NOTA: se puede usar sklearn_model.predict() para obtener directamente las predicciones con las clases.\n",
    "# predict_proba predice la probabilidad de cada muestra y produce el mismo resultado al usar un umbral de 0.5.\n",
    "y_pred_prob_scaled_sklearn = sklearn_model.predict_proba(X_test_scaled)\n",
    "y_pred_scaled_sklearn = [1 if y_pred >= 0.5 else 0 for _, y_pred in y_pred_prob_scaled_sklearn]\n",
    "\n",
    "# Calcular la precisi√≥n del modelo con scikit-learn\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_scaled_sklearn)\n",
    "\n",
    "# Mostrar resultados\n",
    "accuracy_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae7d1c",
   "metadata": {},
   "source": [
    "### Realiza tu conclusiones.\n",
    "El accuracy tiene que ser el mismo o casi el mismo en la implementaci√≥n manual o utilizando la librer√≠a de sklearn.\n",
    "\n",
    "¬øLograste el objetivo?\n",
    "\n",
    "¬øQu√© fue lo m√°s dificil para ti en esta actividad?\n",
    "\n",
    "¬øQu√© fue lo que m√°s te gust√≥?\n",
    "\n",
    "¬øCon qu√© te quedas de esta actividad?\n",
    "\n",
    "¬øEn tus propias palabras qu√© es el accuracy?\n",
    "\n",
    "¬øPodr√≠as decirme cuantos Ciertos positivos tuvo tu modelo?\n",
    "\n",
    "¬øEn el caso de los datos de este estudio qu√© te importa m√°s, los Ciertos postivos, los ciertos falsos, los falsos positivos o los falsos negativos?\n",
    "\n",
    "¬øPara qu√© te sirve la regularizaci√≥n?\n",
    "\n",
    "Investiga en internet en qu√© afecta el sobreajuste a los modelos de clasificaci√≥n. Describe con pocas palabras ¬øPor qu√© es bueno evitar el sobreajuste?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6eaa1",
   "metadata": {},
   "source": [
    "El modelo implementado manualmente obtuvo casi el mismo puntaje de exactitud que el modelo con sklearn (0.9912 y 0.9825, repsectivamente). Esto es un buen indicador de que la implementaci√≥n manual es correcta y de que ambos modelos son efectivos para cumplir con la tarea de clasificaci√≥n asignada. A partir del dataset, los modelos pueden recibir un valores de entrada que no han \"visto\" previamente, y realizar una predicci√≥n de diagn√≥stico con alta certeza.\n",
    "\n",
    "La parte m√°s dif√≠cil fue la implementaci√≥n manual de la funci√≥n de costo. Aunque la funci√≥n en s√≠ no es excesivamente compleja, es importante conocer sobre numpy para aplicar las operaciones correctas, en el orden correcto. Sin embargo, el c√≥digo preestructurado ayuda enormemente a lograrlo.\n",
    "\n",
    "Lo m√°s interesante para m√≠ fue evaluar la exactitud de ambos modelos, porque da una noci√≥n sobre sus efectividades y confianza en las predicciones que hacen. Sobretodo, es uno de los pasos m√°s importantes en aplicaciones reales, especialmente en el √°rea m√©dica donde realizar el diagn√≥stico correcto es muy importante.\n",
    "\n",
    "Esta actividad me permiti√≥ explorar una herramienta b√°sica pero valiosa para ajustar modelos capaces de clasificar datos en dos o m√°s categor√≠as. Adem√°s, refuerza sobre otros conceptos importantes, tales como la optimizaci√≥n, el manejo de conjuntos de datos (separaci√≥n en train y test) y la evaluaci√≥n de los modelos.\n",
    "\n",
    "Para la evaluaci√≥n de los modelos, uno de los conceptos m√°s importantes es el accuracy (exactitud) del modelo. La exactitud es un puntaje que resume el rendimiento del ajuste del modelo a los datos y siempre se busca la forma de maximizar este puntaje. En un modelo de predicci√≥n del clima, podr√≠a representar qu√© tan seguido se equivoca el modelo. A nadie le interesa un modelo que pronostica sol cuando en realidad llueve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f0f8409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El modelo tuvo 45 predicciones positivas verdaderas (114 predicciones en el conjunto de prueba)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive_count = np.sum([1 if y_pred_scaled[i] == 1 and y_test[i] == y_pred_scaled[i] else 0 for i in range(len(y_test))])\n",
    "f\"El modelo tuvo {true_positive_count} predicciones positivas verdaderas ({len(y_test)} predicciones en el conjunto de prueba)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cef23",
   "metadata": {},
   "source": [
    "En el contexto m√©dico de diagn√≥sticos de precursores o indicadores de c√°ncer, las predicciones m√°s importantes son los diagn√≥sticos negativos falsos. Si un paciente verdaderamente est√° desarrollando c√°ncer, la detecci√≥n temprana puede hacer una gran diferencia e incluso salvarle la vida. Si el modelo predice incorrectamente que el paciente no tiene precursores de c√°ncer, el paciente seguir√≠a como si nada y eventualmente padecer√≠a las consecuencias del error.\n",
    "\n",
    "La regularizaci√≥n es √∫til durante el preprocesamiento para ajustar caracter√≠sticas con rangos de valores muy distintos a distribuciones uniformes, usualmente con promedio 0 y desviaci√≥n est√°ndar 1. Evita que una caracter√≠stica tenga influencia excesiva simplemente por tener valores con mayor magnitud.\n",
    "\n",
    "Cuando un modelo de clasificaci√≥n tiene sobreajuste, significa que el ajuste del modelo es demasiado espec√≠fico para el subconjunto de datos de entrenamiento. Esto provoca que el modelo tenga menos exactitud al realizar predicciones con datos que no fueron usados para el ajuste y que no sea generalizable a cualquier conjunto de datos con diferentes valores. Evitar el sobreajuste asegura que el modelo pueda ser aplicable fuera del entrenamiento y ajuste inicial y, por lo tanto, √∫til."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv.nosync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
